## â— Project Limitations

Although the system performs well for simple cases, several limitations affect its real-world performance and generalization:

---

### ğŸ”¹ **1. Limited Dataset Coverage**
- Dataset lacks common contractions (donâ€™t, wonâ€™t, Iâ€™m)  
- Reduces performance on informal or natural text  

---

### ğŸ”¹ **2. Short and Biased Samples**
- Training examples are very short  
- Model struggles with long, complex, or conversational sentences  

---

### ğŸ”¹ **3. Only Six Emotion Categories**
Current emotions: ğŸ˜Š joy â€¢ ğŸ˜¢ sadness â€¢ â¤ï¸ love â€¢ ğŸ˜¡ anger â€¢ ğŸ˜¨ fear â€¢ ğŸ˜® surprise  
Missing important categories such as:
- disgust  
- confusion  
- anticipation  
- trust  

â†’ Emotional nuance is limited.

---

### ğŸ”¹ **4. Sentiment Labels Are Rule-Based**
- Sentiment is assigned using simple mapping rules, not learned  
- Cannot detect subtle or mixed sentiment (e.g., â€œhappy but tiredâ€)  

---

### ğŸ”¹ **5. Bag-of-Words Models Ignore Context**
- Logistic Regression & Naive Bayes remove word order  
Fails with:
- negation (â€œnot happyâ€)  
- sarcasm  
- context-dependent meaning  

---

### ğŸ”¹ **6. BiLSTM Vocabulary Limitations**
- Uses a fixed vocabulary  
- Unseen words become `<UNK>`  
- Performance drops on slang, typos, or domain-specific terms  

---

### ğŸ”¹ **7. Aggressive Text Cleaning Removes Emotional Cues**
Removed during preprocessing:
- emojis ğŸ™‚ğŸ˜¡ğŸ˜¢  
- punctuation (! ? â€¦)  
- repeated characters (â€œsoooo happyâ€)  

These carry emotional meaning â†’ removing them reduces accuracy.

---

## **Summary**
The system works well in controlled settings but struggles with:
- messy, real-world text  
- long inputs  
- subtle emotional signals  
- unseen vocabulary  
- nuanced sentiment  

Improving data quality, vocabulary handling, and model complexity would significantly improve results.
